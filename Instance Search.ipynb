{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colour Histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "path_query = 'datasets/query/'\n",
    "path_query_txt = 'datasets/query_txt/'\n",
    "path_gallery = 'dataset/gallery/'\n",
    "\n",
    "name_query = glob.glob(path_query+'*.jpg')\n",
    "num_query = len(name_query)\n",
    "name_gallery = glob.glob(path_gallery+'*.jpg')\n",
    "num_gallery = len(name_gallery)\n",
    "\n",
    "def crop(path):\n",
    "    img = cv.imread(path)\n",
    "    txtIndex = path.split('.')[0].split('/')\n",
    "    content = []\n",
    "\n",
    "    with open('datasets/query_txt/' + txtIndex[-1] + \".txt\", 'r') as f:\n",
    "        content = f.read().split()\n",
    "\n",
    "    x = int(content[0])\n",
    "    y = int(content[1])\n",
    "    w = int(content[2])\n",
    "    h = int(content[3])\n",
    "    img = img[y : y + h, x : x + w]\n",
    "    return img\n",
    "\n",
    "def widthAndHeight(path):\n",
    "    txtIndex = path.split('.')[0].split('/')\n",
    "    content = []\n",
    "\n",
    "    with open('datasets/query_txt/' + txtIndex[-1] + \".txt\", 'r') as f:\n",
    "        content = f.read().split()\n",
    "\n",
    "    w = int(content[2])\n",
    "    h = int(content[3])\n",
    "    return (w, h)\n",
    "\n",
    "def HSVHistogram(img):\n",
    "    Hist = []\n",
    "    hue = np.zeros((180), dtype=int)\n",
    "    saturation = np.zeros((256), dtype=int)\n",
    "    value = np.zeros((256), dtype=int)\n",
    "\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    for j in range(height):\n",
    "        for k in range(width):\n",
    "            h = img[j][k][0]\n",
    "            s = img[j][k][1]\n",
    "            v = img[j][k][2]\n",
    "            hue[h] += 1\n",
    "            saturation[s] += 1\n",
    "            value[v] += 1\n",
    "\n",
    "    cv.normalize(hue, hue, alpha=2500, beta=0, norm_type=cv.NORM_L2)\n",
    "    cv.normalize(saturation, saturation, alpha=2500, beta=0, norm_type=cv.NORM_L2)\n",
    "    cv.normalize(value, value, alpha=2500, beta=0, norm_type=cv.NORM_L2)\n",
    "\n",
    "    Hist.extend(hue)\n",
    "    Hist.extend(saturation)\n",
    "    Hist.extend(value)\n",
    "    return Hist\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "\tfor y in range(0, image.shape[0] - windowSize[1], stepSize):\n",
    "\t\tfor x in range(0, image.shape[1] - windowSize[0], stepSize):\n",
    "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_allQuery = np.zeros((num_query, 10))\n",
    "\n",
    "for n in range(num_query):\n",
    "    similarity = []\n",
    "    bgr_qry = crop(name_query[n])\n",
    "    (winW, winH) = widthAndHeight(name_query[n])\n",
    "    img_qry = cv.cvtColor(bgr_qry, cv.COLOR_BGR2HSV)\n",
    "    Hist_qry = HSVHistogram(img_qry)\n",
    "\n",
    "    for i in tqdm(range(num_gallery)):\n",
    "        bgr = cv.imread(name_gallery[i], cv.IMREAD_COLOR)\n",
    "        img = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)\n",
    "        sim_single = []\n",
    "\n",
    "        for (x, y, window) in sliding_window(img, stepSize=64, windowSize=(winW, winH)):\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "\n",
    "            Hist_gal = HSVHistogram(window)\n",
    "            cos_sim = np.inner(Hist_qry, Hist_gal)/(norm(Hist_qry)*norm(Hist_gal))\n",
    "            sim_single.append(cos_sim)\n",
    "\n",
    "        max_sim = max(sim_single, default = 0)\n",
    "        similarity.append(max_sim)\n",
    "    descend_index = sorted(range(len(similarity)), key = lambda k: similarity[k], reverse=True)\n",
    "    descend_name_gallery = [name_gallery[index].split('.')[0].split('/')[-1] for index in descend_index[0:10]]\n",
    "    rank_allQuery[n, :] = descend_name_gallery\n",
    "\n",
    "f = open('rankList_hsv.txt', 'w')\n",
    "for i in range(num_query):\n",
    "    f.write('Query '+str(i + 1)+': ')\n",
    "    for j in range(10):\n",
    "        f.write(str(np.int32(rank_allQuery[i, j])) + ' ')\n",
    "    f.write('\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Networks (VGG-16)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "    def extract(self, img):\n",
    "        img = img.resize((224, 224))\n",
    "        img = img.convert('RGB')\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        feature = self.model.predict(x)[0]\n",
    "        return (feature / np.linalg.norm(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_query = 'drive/MyDrive/datasets/query/'\n",
    "path_query_txt = 'drive/MyDrive/datasets/query_txt/'\n",
    "path_gallery = 'drive/MyDrive/datasets/gallery/'\n",
    "\n",
    "name_query = glob.glob(path_query+'*.jpg')\n",
    "num_query = len(name_query)\n",
    "name_gallery = glob.glob(path_gallery+'*.jpg')\n",
    "num_gallery = len(name_gallery)\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "for i in tqdm(range(num_gallery)):\n",
    "    img_gal = Image.open(name_gallery[i])\n",
    "    feature = fe.extract(img=img_gal)\n",
    "    feature_path = 'drive/MyDrive/datasets/gallery_feature/' + name_gallery[i].split('.')[0].split('/')[-1] + '.npy'\n",
    "    np.save(feature_path, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_allQuery = np.zeros((num_query, 10))\n",
    "\n",
    "for n in range(num_query):\n",
    "    dist = []\n",
    "    img_qry = Image.open(name_query[n])\n",
    "    feat_qry = fe.extract(img=img_qry)\n",
    "\n",
    "    for i in tqdm(range(num_gallery)):\n",
    "        feat_gal = np.load('drive/MyDrive/datasets/gallery_feature/'+name_gallery[i].split('.')[0].split('/')[-1]+'.npy')\n",
    "        distance = np.linalg.norm(feat_gal - feat_qry, axis=0)\n",
    "        dist.append(distance)\n",
    "    ascend_index = sorted(range(len(dist)), key = lambda k: dist[k])\n",
    "    ascend_name_gallery = [name_gallery[index].split('.')[0].split('/')[-1] for index in ascend_index[0:10]]\n",
    "    rank_allQuery[n, :] = ascend_name_gallery\n",
    "\n",
    "f = open('rankList_CNN.txt', 'w')\n",
    "for i in range(num_query):\n",
    "    f.write('Query '+str(i + 1)+': ')\n",
    "    for j in range(10):\n",
    "        f.write(str(np.int32(rank_allQuery[i, j])) + ' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG-16 and Scale-Invariant Feature Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "path_query = 'drive/MyDrive/datasets/query/'\n",
    "path_query_txt = 'drive/MyDrive/datasets/query_txt/'\n",
    "path_gallery = 'drive/MyDrive/datasets/gallery/'\n",
    "\n",
    "name_query = glob.glob(path_query+'*.jpg')\n",
    "num_query = len(name_query)\n",
    "name_gallery = glob.glob(path_gallery+'*.jpg')\n",
    "num_gallery = len(name_gallery)\n",
    "\n",
    "def crop(path):\n",
    "    img = cv.imread(path)\n",
    "    txtIndex = path.split('.')[0].split('/')\n",
    "    content = []\n",
    "\n",
    "    with open(path_query_txt + txtIndex[-1] + \".txt\", 'r') as f:\n",
    "        content = f.read().split()\n",
    "\n",
    "    x = int(content[0])\n",
    "    y = int(content[1])\n",
    "    w = int(content[2])\n",
    "    h = int(content[3])\n",
    "    img = img[y : y + h, x : x + w]\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.SIFT_create()\n",
    "for i in tqdm(range(num_gallery)):\n",
    "    img_gal = cv.imread(name_gallery[i])\n",
    "    gray_gal = cv.cvtColor(img_gal, cv.COLOR_BGR2GRAY)\n",
    "    kp_gal, des_gal = sift.detectAndCompute(gray_gal, None)\n",
    "    feature_path = 'drive/MyDrive/datasets/gallery_feature_SIFT/' + name_gallery[i].split('.')[0].split('/')[-1] + '.npy'\n",
    "    np.save(feature_path, des_gal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_allQuery = np.zeros((num_query, 10))\n",
    "sift = cv.SIFT_create()\n",
    "fe = FeatureExtractor()\n",
    "for n in range(num_query):\n",
    "    dist = []\n",
    "    img_qry = Image.open(name_query[n])\n",
    "    feat_qry = fe.extract(img=img_qry)\n",
    "\n",
    "    img_qry = crop(name_query[n])\n",
    "    gray_qry = cv.cvtColor(img_qry, cv.COLOR_BGR2GRAY)\n",
    "    kp_qry, des_qry = sift.detectAndCompute(gray_qry, None)\n",
    "\n",
    "    for i in tqdm(range(num_gallery)):\n",
    "        feat_gal = np.load('drive/MyDrive/datasets/gallery_feature/'+name_gallery[i].split('.')[0].split('/')[-1]+'.npy')\n",
    "        Distance = np.linalg.norm(feat_gal - feat_qry, axis=0)\n",
    "\n",
    "        des_gal = np.load('drive/MyDrive/datasets/gallery_feature_SIFT/'+name_gallery[i].split('.')[0].split('/')[-1]+'.npy')\n",
    "        bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)\n",
    "        matches = bf.match(des_gal, des_qry)\n",
    "        num_matches = len(matches)\n",
    "        dist_list = [DMatch.distance for DMatch in matches]\n",
    "        dist_l2 = sum(dist_list) / num_matches\n",
    "        dist.append(dist_l2 + Distance)\n",
    "\n",
    "    ascend_index = sorted(range(len(dist)), key = lambda k: dist[k])\n",
    "    ascend_name_gallery = [name_gallery[index].split('.')[0].split('/')[-1] for index in ascend_index[0:10]]\n",
    "    rank_allQuery[n, :] = ascend_name_gallery\n",
    "\n",
    "f = open('drive/MyDrive/rankList_CNN+SIFT.txt', 'w')\n",
    "for i in range(num_query):\n",
    "    f.write('Query '+str(i + 1)+': ')\n",
    "    for j in range(10):\n",
    "        f.write(str(np.int32(rank_allQuery[i, j])) + ' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f596f28eb1fb751d09c79d08895e1f909decb5402d4423f3d5949c13094948cd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
